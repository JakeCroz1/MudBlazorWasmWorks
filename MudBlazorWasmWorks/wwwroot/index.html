<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <title>MudBlazorWasmWorks</title>
    <base href="/" />
    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap" rel="stylesheet" />
    <link href="_content/MudBlazor/MudBlazor.min.css" rel="stylesheet" />
    <link href="MudBlazorWasmWorks.styles.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/p5.js"></script>
    <script src="/scripts/p5sound.js"></script>
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.6.0/addons/p5.sound.min.js"></script>-->
</head>

<body>
    <div id="app">Loading...</div>

    <div id="blazor-error-ui">
        An unhandled error has occurred.
        <a href="" class="reload">Reload</a>
        <a class="dismiss">ðŸ—™</a>
    </div>
    <button onclick="startMic()" style="background-color:aqua; width:100%; height: 50px; ">click</button>
    <script>
        let amplitude; // variable to hold the amplitude values
        var freqValue;
        let fft;
        let mic;
        /*
        function preload() {
          song = loadSound('https://beststorageever2020.blob.core.windows.net/video4/Tones.mp3'); // load the sound file
        }
        */
        function setup() {
            createCanvas(400, 400); // create a canvas
            userStartAudio();
            mic = new p5.AudioIn();
            amplitude = new p5.Amplitude(0.5);
            mic.start();
            // p5.PeakDetect requires a p5.FFT
            fft = new p5.FFT();
            fft.setInput(mic);
            //fft = new p5.FFT();
            mic.connect(amplitude)
            // create a new Amplitude object
            //filter = new p5.LowPass(); // create a new LowPass filter object
            //song.connect(filter); // connect the sound file to the filter

            //song.play(); // play the sound file
        }

        function draw() {
            background(220); // set the background color
            // get the average value in a frequency range
            let spectrum = fft.analyze();
            //freqValue = fft.getEnergy("bass", 40); 
            let level = amplitude.getLevel(); // get the current level of the amplitude
            let size = map(level, 0, 1, 10, 200); // map the level to a size for the ellipse

            fill(255, 0, 0); // set the fill color to red
            ellipse(width / 2, height / 2, size, size); // draw the ellipse in the center of the canvas
            //for (let i = 0; i< spectrum.length; i++){


            //console.log(spectrum[i]);

            //}
            // detect the beat
            if (level > 0.2) {
                // do something when a beat is detected
                window.ReactNativeWebView.postMessage('callReactNativeFunction');
                console.log("Beat detected!");
            }
        }
        /*
        const avgWindow = 20;
        const threshold = 0.28;
        let fft;
        let beat;
        let lastPeak;
        let mic;

        function setup() {
            createCanvas(400, 400);
            userStartAudio();
            mic = new p5.AudioIn();
            mic.start();
            // p5.PeakDetect requires a p5.FFT
            fft = new p5.FFT();
            fft.setInput(mic);
            beat = millis();
        }

        function draw() {
            // Pulse white on the beat, then fade out with an inverse cube curve
            background(map(1 / pow((millis() - beat) / 1000 + 1, 3), 1, 0, 255, 100));
            drawSpectrumGraph(0, 0, width, height);
        }

        let i = 0;
        // Graphing code adapted from https://jankozeluh.g6.cz/index.html by Jan KoÅ¾eluh
        function drawSpectrumGraph(left, top, w, h) {
            let spectrum = fft.analyze();

            stroke('limegreen');
            fill('darkgreen');
            strokeWeight(1);

            beginShape();
            vertex(left, top + h);

            let peak = 0;
            // compute a running average of values to avoid very
            // localized energy from triggering a beat.
            let runningAvg = 0;
            for (let i = 0; i < spectrum.length; i++) {
                vertex(
                    //left + map(i, 0, spectrum.length, 0, w),
                    // Distribute the spectrum values on a logarithmic scale
                    // We do this because as you go higher in the spectrum
                    // the same perceptible difference in tone requires a 
                    // much larger chang in frequency.
                    left + map(log(i), 0, log(spectrum.length), 0, w),
                    // Spectrum values range from 0 to 255
                    top + map(spectrum[i], 0, 255, h, 0)
                );

                runningAvg += spectrum[i] / avgWindow;
                if (i >= avgWindow) {
                    runningAvg -= spectrum[i] / avgWindow;
                }
                if (runningAvg > peak) {
                    peak = runningAvg;
                }
            }

            // any time there is a sudden increase in peak energy, call that a beat
            if (peak > lastPeak * (1 + threshold)) {               
                window.ReactNativeWebView.postMessage('callReactNativeFunction');
                console.log("beat");
                beat = millis();
            }
            lastPeak = peak;

            vertex(left + w, top + h);
            endShape(CLOSE);
            // this is the range of frequencies covered by the FFT
            let nyquist = 22050;

            // get the centroid (value in hz)
            let centroid = fft.getCentroid();

            // the mean_freq_index calculation is for the display.
            // centroid frequency / hz per bucket
            let mean_freq_index = centroid / (nyquist / spectrum.length);
            stroke('red');
            // convert index to x value using a logarithmic x axis
            let cx = map(log(mean_freq_index), 0, log(spectrum.length), 0, width);
            line(cx, 0, cx, h);
        }*/
        /*
        var mic, fft;

        function setup() {
            createCanvas(512, 400);
            noStroke();
            fill(0, 255, 255);
            userStartAudio();
            mic = new p5.AudioIn();
            //getAudioContext().resume();
            mic.start();
            fft = new p5.FFT();
            fft.setInput(mic);
        }

        function draw() {
            background(200);
            var spectrum = fft.analyze();

            beginShape();
            vertex(0, height);
            for (i = 0; i < spectrum.length; i++) {
                vertex(i, map(spectrum[i], 0, 255, height, 0));
            }
            endShape();

        }
        */
    </script>
    <script src="_framework/blazor.webassembly.js"></script>
    <script src="_content/MudBlazor/MudBlazor.min.js"></script>
</body>

</html>